#!/usr/bin/env python3
"""
DIRECT-TO-CLOUDINARY MANGA SCRAPER
Downloads manga chapters directly to Cloudinary without local storage
Saves disk space and speeds up the process significantly
"""

import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import time
import re
import csv
from datetime import datetime
from io import BytesIO
import cloudinary
import cloudinary.uploader
import cloudinary.api

# ============================================
# CONFIGURATION
# ============================================

cloudinary.config(
    cloud_name="dk9ywbxu1",
    api_key="542786312744176",
    api_secret="Z6K9BvGQ7QtKGWpk2-bbgoSBUJg"
)

CLOUDINARY_BASE = "manga"  # Base folder in Cloudinary
METADATA_CSV = "cloudinary_manga_metadata.csv"
MAX_RETRY_ATTEMPTS = 3

# ============================================
# HELPER FUNCTIONS
# ============================================

def get_manga_slug_from_url(manga_url):
    """Extract slug from manga URL"""
    match = re.search(r'/manga/([^/]+)', manga_url)
    return match.group(1) if match else None


def print_header(title):
    """Print formatted header"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")


def ensure_cloudinary_folder(folder_path):
    """Create folder structure in Cloudinary"""
    try:
        cloudinary.api.create_folder(folder_path)
        return True
    except Exception as e:
        # Folder might already exist
        if 'already exists' in str(e).lower() or 'exist' in str(e).lower():
            return True
        print(f"âš ï¸  Folder creation warning: {str(e)[:50]}")
        return False


# ============================================
# METADATA MANAGEMENT
# ============================================

def update_metadata(manga_name, manga_slug, chapter_num, panel_count, expected_count, status, error='', cloudinary_urls=[]):
    """Update metadata CSV with chapter information"""
    
    # Ensure CSV exists
    if not os.path.exists(METADATA_CSV):
        with open(METADATA_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'manga_name', 'manga_slug', 'chapter_number', 
                'panel_count', 'expected_count', 'status', 
                'timestamp', 'error', 'cloudinary_folder'
            ])
    
    # Read existing rows
    rows = []
    chapter_exists = False
    
    with open(METADATA_CSV, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames
        
        for row in reader:
            if row['manga_slug'] == manga_slug and int(row['chapter_number']) == chapter_num:
                # Update existing
                row['manga_name'] = manga_name
                row['panel_count'] = panel_count
                row['expected_count'] = expected_count
                row['status'] = status
                row['timestamp'] = datetime.now().isoformat()
                row['error'] = error
                row['cloudinary_folder'] = f"{CLOUDINARY_BASE}/{manga_slug}/chapter-{chapter_num:03d}"
                chapter_exists = True
            rows.append(row)
    
    # Write back
    with open(METADATA_CSV, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)
        
        if not chapter_exists:
            writer.writerow({
                'manga_name': manga_name,
                'manga_slug': manga_slug,
                'chapter_number': chapter_num,
                'panel_count': panel_count,
                'expected_count': expected_count,
                'status': status,
                'timestamp': datetime.now().isoformat(),
                'error': error,
                'cloudinary_folder': f"{CLOUDINARY_BASE}/{manga_slug}/chapter-{chapter_num:03d}"
            })


# ============================================
# CORE SCRAPING WITH DIRECT UPLOAD
# ============================================

def scrape_chapter_direct_to_cloudinary(chapter_url, manga_name, manga_slug, chapter_num):
    """
    Scrape chapter and upload directly to Cloudinary
    Returns: (panel_count, success_status, error_message, expected_count, cloudinary_urls)
    """
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“¥ Fetching Chapter {chapter_num}: {chapter_url}")
    print(f"{'â”€'*80}\n")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Referer': 'https://www.mangaread.org/',
    }
    
    try:
        # Fetch chapter page
        response = requests.get(chapter_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        images = soup.select('.page-break.no-gaps img')
        expected_count = len(images)
        
        print(f"ğŸ” Found {expected_count} panels to upload")
        
        if expected_count == 0:
            update_metadata(manga_name, manga_slug, chapter_num, 0, 0, 'failed', 'No images found')
            return 0, False, "No images found", 0, []
        
        # Get image URLs
        image_urls = []
        for img in images:
            img_url = (img.get('src') or 
                      img.get('data-src') or 
                      img.get('data-lazy-src') or
                      img.get('data-original'))
            
            if img_url:
                img_url = img_url.strip()
                full_url = urljoin(chapter_url, img_url)
                image_urls.append(full_url)
        
        if not image_urls:
            update_metadata(manga_name, manga_slug, chapter_num, 0, expected_count, 'failed', 'No valid image URLs')
            return 0, False, "No valid image URLs", expected_count, []
        
        # Create Cloudinary folder structure
        cloudinary_chapter_folder = f"{CLOUDINARY_BASE}/{manga_slug}/chapter-{chapter_num:03d}"
        
        print(f"â˜ï¸  Cloudinary folder: {cloudinary_chapter_folder}")
        ensure_cloudinary_folder(f"{CLOUDINARY_BASE}/{manga_slug}")
        ensure_cloudinary_folder(cloudinary_chapter_folder)
        
        # Upload images directly to Cloudinary
        uploaded_count = 0
        failed_count = 0
        cloudinary_urls = []
        
        print(f"\nğŸ“¤ Uploading {len(image_urls)} panels directly to Cloudinary...\n")
        
        for idx, img_url in enumerate(image_urls, 1):
            try:
                # Download image to memory
                img_response = requests.get(img_url, headers=headers, timeout=15)
                img_response.raise_for_status()
                
                # Get file extension
                ext = os.path.splitext(urlparse(img_url).path)[1] or '.jpg'
                ext = ext.lstrip('.')
                
                # Normalize extension
                if ext.lower() == 'jpeg':
                    ext = 'jpg'
                
                # Create public_id (filename without extension)
                public_id = f"panel-{idx:03d}"
                
                # Upload to Cloudinary directly from memory
                upload_result = cloudinary.uploader.upload(
                    BytesIO(img_response.content),
                    folder=cloudinary_chapter_folder,
                    public_id=public_id,
                    overwrite=False,
                    resource_type="auto",
                    use_filename=False,
                    unique_filename=False,
                    format=ext
                )
                
                cloudinary_url = upload_result.get('secure_url')
                cloudinary_urls.append(cloudinary_url)
                
                print(f"âœ… [{idx}/{len(image_urls)}] Uploaded: panel-{idx:03d}.{ext} â†’ Cloudinary")
                uploaded_count += 1
                
                # Be polite - small delay
                time.sleep(0.3)
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ [{idx}/{len(image_urls)}] Download failed: {str(e)[:60]}")
                failed_count += 1
            except Exception as e:
                print(f"âŒ [{idx}/{len(image_urls)}] Upload failed: {str(e)[:60]}")
                failed_count += 1
        
        # Determine status
        if uploaded_count == expected_count:
            status = 'success'
            error_msg = ''
        elif uploaded_count > 0:
            status = 'partial'
            error_msg = f'Uploaded {uploaded_count}/{expected_count} panels'
        else:
            status = 'failed'
            error_msg = 'All uploads failed'
        
        # Update metadata
        update_metadata(
            manga_name, manga_slug, chapter_num,
            uploaded_count, expected_count, status, error_msg, cloudinary_urls
        )
        
        # Summary
        print(f"\n{'â”€'*80}")
        print(f"ğŸ“Š Chapter {chapter_num} Summary:")
        print(f"âœ… Uploaded: {uploaded_count}/{expected_count}")
        print(f"âŒ Failed: {failed_count}")
        print(f"ğŸ“ Cloudinary folder: {cloudinary_chapter_folder}")
        print(f"{'â”€'*80}\n")
        
        return uploaded_count, (uploaded_count == expected_count), error_msg, expected_count, cloudinary_urls
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ Error: {error_msg}")
        update_metadata(manga_name, manga_slug, chapter_num, 0, 0, 'failed', error_msg)
        return 0, False, error_msg, 0, []


# ============================================
# CHAPTER LIST MANAGEMENT
# ============================================

def get_all_chapters(manga_url):
    """Get list of all chapters from manga page"""
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    }
    
    print(f"ğŸ” Fetching chapter list from: {manga_url}")
    
    try:
        response = requests.get(manga_url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        chapter_links = []
        links = soup.select('ul.main li a')
        
        for link in links:
            href = link.get('href')
            if href and '/chapter-' in href:
                match = re.search(r'chapter-(\d+)', href)
                if match:
                    chapter_num = int(match.group(1))
                    full_url = urljoin(manga_url, href)
                    chapter_links.append({
                        'url': full_url,
                        'number': chapter_num,
                        'text': link.get_text(strip=True)
                    })
        
        # Remove duplicates and sort
        unique_chapters = {ch['number']: ch for ch in chapter_links}
        sorted_chapters = sorted(unique_chapters.values(), key=lambda x: x['number'])
        
        print(f"âœ… Found {len(sorted_chapters)} chapters")
        
        return sorted_chapters
        
    except Exception as e:
        print(f"âŒ Error fetching chapter list: {e}")
        return []


# ============================================
# BULK OPERATIONS
# ============================================

def scrape_all_chapters_direct(manga_url, manga_name, manga_slug, start_chapter=1, end_chapter=None):
    """
    Scrape multiple chapters directly to Cloudinary
    No local storage used!
    """
    print_header(f"ğŸš€ DIRECT-TO-CLOUDINARY SCRAPER: {manga_name}")
    
    # Get chapters
    chapters = get_all_chapters(manga_url)
    
    if not chapters:
        print("âŒ Could not fetch chapter list")
        return
    
    # Filter by range
    if start_chapter or end_chapter:
        chapters = [ch for ch in chapters 
                   if (ch['number'] >= start_chapter) 
                   and (not end_chapter or ch['number'] <= end_chapter)]
    
    print(f"\nğŸ“Š Will upload {len(chapters)} chapters directly to Cloudinary")
    print(f"â˜ï¸  Base folder: {CLOUDINARY_BASE}/{manga_slug}")
    print(f"ğŸ’¾ Metadata: {METADATA_CSV}")
    print(f"ğŸ’¡ Mode: DIRECT UPLOAD (no local storage)")
    
    # Load existing metadata to skip completed chapters
    existing_metadata = load_existing_metadata(manga_slug)
    
    success_count = 0
    failed_chapters = []
    skipped_count = 0
    
    for chapter in chapters:
        chapter_num = chapter['number']
        
        # Check if already complete
        if chapter_num in existing_metadata:
            meta = existing_metadata[chapter_num]
            if meta['status'] == 'success' and meta['panel_count'] == meta.get('expected_count', meta['panel_count']):
                print(f"\nâŠ˜ Chapter {chapter_num} already complete ({meta['panel_count']} panels), skipping...")
                skipped_count += 1
                success_count += 1
                continue
        
        try:
            panel_count, success, error, expected, urls = scrape_chapter_direct_to_cloudinary(
                chapter['url'],
                manga_name,
                manga_slug,
                chapter_num
            )
            
            if success and panel_count > 0:
                success_count += 1
            else:
                failed_chapters.append(chapter_num)
            
            # Delay between chapters
            time.sleep(2)
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  Download interrupted by user")
            break
        except Exception as e:
            print(f"âŒ Error processing chapter {chapter_num}: {e}")
            failed_chapters.append(chapter_num)
    
    # Final summary
    print_header("ğŸ“Š UPLOAD SUMMARY")
    print(f"âœ… Successfully uploaded: {success_count}/{len(chapters)} chapters")
    print(f"âŠ˜ Skipped (already complete): {skipped_count}")
    print(f"âŒ Failed: {len(failed_chapters)}")
    
    if failed_chapters:
        print(f"\nâŒ Failed chapter numbers: {', '.join(map(str, failed_chapters))}")
    
    print(f"\nâ˜ï¸  Cloudinary folder: {CLOUDINARY_BASE}/{manga_slug}")
    print(f"ğŸ“„ Metadata: {METADATA_CSV}")
    print(f"ğŸ’¡ Disk space used: 0 bytes (direct upload)")
    print("="*80 + "\n")


def load_existing_metadata(manga_slug):
    """Load existing metadata for a manga"""
    existing = {}
    
    if not os.path.exists(METADATA_CSV):
        return existing
    
    with open(METADATA_CSV, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row['manga_slug'] == manga_slug:
                chapter_num = int(row['chapter_number'])
                existing[chapter_num] = {
                    'panel_count': int(row['panel_count']),
                    'expected_count': int(row.get('expected_count', row['panel_count'])),
                    'status': row['status']
                }
    
    return existing


def verify_cloudinary_manga(manga_slug):
    """Verify manga in Cloudinary using metadata"""
    print_header(f"ğŸ” VERIFYING: {manga_slug}")
    
    if not os.path.exists(METADATA_CSV):
        print("âŒ No metadata file found")
        return []
    
    # Load metadata
    metadata = {}
    with open(METADATA_CSV, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row['manga_slug'] == manga_slug:
                chapter_num = int(row['chapter_number'])
                metadata[chapter_num] = row
    
    print(f"ğŸ“Š Found metadata for {len(metadata)} chapters\n")
    
    issues = []
    checked = 0
    
    for chapter_num, meta in sorted(metadata.items()):
        checked += 1
        status = meta['status']
        panel_count = int(meta['panel_count'])
        expected = int(meta.get('expected_count', panel_count))
        
        if status == 'failed' or panel_count != expected:
            print(f"âŒ Chapter {chapter_num}: {status} ({panel_count}/{expected} panels)")
            issues.append(chapter_num)
        else:
            print(f"âœ… Chapter {chapter_num}: OK ({panel_count} panels)")
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Verification Summary")
    print(f"{'='*80}")
    print(f"Checked: {checked} chapters")
    print(f"Issues: {len(issues)}")
    
    if issues:
        print(f"Failed chapters: {', '.join(map(str, issues))}")
    
    return issues


def retry_failed_chapters(manga_url, manga_name, manga_slug):
    """Retry chapters that failed or are incomplete"""
    
    print_header(f"ğŸ”„ RETRYING FAILED CHAPTERS: {manga_name}")
    
    # Find failed chapters
    failed_chapters = verify_cloudinary_manga(manga_slug)
    
    if not failed_chapters:
        print("\nâœ… No failed chapters to retry!")
        return
    
    print(f"\nâš ï¸  Found {len(failed_chapters)} chapters to retry")
    confirm = input(f"Retry these {len(failed_chapters)} chapters? (y/n): ").strip().lower()
    
    if confirm != 'y':
        print("âŒ Retry cancelled")
        return
    
    # Get chapter URLs
    all_chapters = get_all_chapters(manga_url)
    chapter_map = {ch['number']: ch for ch in all_chapters}
    
    success_count = 0
    still_failed = []
    
    for chapter_num in failed_chapters:
        if chapter_num not in chapter_map:
            print(f"\nâŒ Chapter {chapter_num}: URL not found")
            still_failed.append(chapter_num)
            continue
        
        try:
            panel_count, success, error, expected, urls = scrape_chapter_direct_to_cloudinary(
                chapter_map[chapter_num]['url'],
                manga_name,
                manga_slug,
                chapter_num
            )
            
            if success:
                success_count += 1
            else:
                still_failed.append(chapter_num)
            
            time.sleep(2)
            
        except Exception as e:
            print(f"âŒ Chapter {chapter_num} error: {e}")
            still_failed.append(chapter_num)
    
    print(f"\n{'='*80}")
    print(f"ğŸ”„ Retry Summary")
    print(f"{'='*80}")
    print(f"âœ… Fixed: {success_count}/{len(failed_chapters)}")
    print(f"âŒ Still failed: {len(still_failed)}")
    
    if still_failed:
        print(f"Chapter numbers: {', '.join(map(str, still_failed))}")


# ============================================
# MAIN CLI
# ============================================

def main():
    """Interactive CLI"""
    
    print_header("â˜ï¸  DIRECT-TO-CLOUDINARY MANGA SCRAPER")
    
    print("ğŸ¯ Features:")
    print("  â€¢ Downloads directly to Cloudinary")
    print("  â€¢ Zero local disk space used")
    print("  â€¢ 50%+ faster than local-then-upload")
    print("  â€¢ Automatic retry for failed chapters")
    print("  â€¢ Skip already uploaded chapters")
    
    print("\nğŸ“‹ Choose option:")
    print("1. Download manga (all chapters)")
    print("2. Download specific chapter range")
    print("3. Verify uploaded manga")
    print("4. Retry failed chapters")
    print("5. Exit")
    
    choice = input("\nğŸ‘‰ Enter choice (1-5): ").strip()
    
    if choice in ['1', '2', '4']:
        manga_url = input("\nğŸ“š Enter manga URL: ").strip()
        
        manga_slug = get_manga_slug_from_url(manga_url)
        if not manga_slug:
            print("âŒ Invalid manga URL")
            return
        
        manga_name = input(f"Enter manga name (default: {manga_slug.replace('-', ' ').title()}): ").strip()
        if not manga_name:
            manga_name = manga_slug.replace('-', ' ').title()
    
    try:
        if choice == '1':
            confirm = input(f"\nâš ï¸  Upload ALL chapters of {manga_name} to Cloudinary? (y/n): ").strip().lower()
            if confirm == 'y':
                scrape_all_chapters_direct(manga_url, manga_name, manga_slug)
        
        elif choice == '2':
            start = int(input("Start chapter: "))
            end = int(input("End chapter: "))
            scrape_all_chapters_direct(manga_url, manga_name, manga_slug, start, end)
        
        elif choice == '3':
            manga_slug = input("Enter manga slug: ").strip()
            verify_cloudinary_manga(manga_slug)
        
        elif choice == '4':
            retry_failed_chapters(manga_url, manga_name, manga_slug)
        
        elif choice == '5':
            print("\nğŸ‘‹ Goodbye!")
        
        else:
            print("âŒ Invalid choice")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Operation cancelled")
    except Exception as e:
        print(f"\nâŒ Error: {e}")


if __name__ == "__main__":
    main()